<!DOCTYPE html>
<html lang="en-us">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <title>
About James Chua | James Chua
</title>

    <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">

<meta name="generator" content="Hugo 0.124.0">


<link rel="canonical" href="//localhost:1313/about/" >




<link href="/css/style.min.d23c1980faa61c0d6b331a0cd9dbc34fb7dade9e294067f1108fb8f26bd7796c.css" rel="stylesheet">




</head>

<body>

    <div class="flexWrapper">
        <header class="headerWrapper">
    <div class="header">
        
        <input class="side-menu" type="checkbox" id="side-menu">
        <label class="hamb" for="side-menu"><span class="hamb-line"></span></label>
        <nav class="headerLinks">
            <ul>
                
                <li>
                    <a href="//localhost:1313/about" title="" >
                        ~/about</a>
                </li>
                
                <li>
                    <a href="//localhost:1313/blog" title="" >
                        ~/blog</a>
                </li>
                
            </ul>
        </nav>
    </div>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F5HRB2FFK4"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-F5HRB2FFK4');
    </script>
</header>


        <div class="content">
            <main class="main">
                
<div class="postWrapper">
    <h1>About James Chua</h1>
    
    
    <section class="postMetadata">
        <dl>
            
            
            
            
            
                
                <dt>published</dt>
                
                <dd><time datetime="2025-02-08">February 8, 2025</time></dd>
                
            
            
                
                
            
        </dl>
    </section>
    
    <div>
        <!-- raw HTML omitted -->
<figure><img src="/about/images/me.png" width="200px">
</figure>

<p>Hi! I&rsquo;m working as an alignment researcher at <a href="https://www.truthfulai.org">TruthfulAI, a new org in Berkeley headed by Owain Evans.</a>.
Before this, I worked as an Anthropic Contractor as part of the MATS 2023 program under <a href="https://ethanperez.net">Ethan Perez</a>.
In a previous life, I&rsquo;ve worked as a machine learning engineer (LeadiQ 2020-2023).
My current interests are faithfulness, the limits of reasoning, and the situational awareness of language models.</p>
<p>I enjoy making typesafe python packages such as <a href="https://github.com/thejaminator/slist">Slist</a> on the side.</p>
<h2 id="links">Links</h2>
<p><a href="https://scholar.google.com/citations?user=tv6Se-gAAAAJ&amp;hl=en">Google Scholar</a> | <a href="https://x.com/jameschua_sg">Twitter</a> | <a href="https://xiaohongshu.com/user/profile/65d0f7c20000000005032f7d">小红书</a>｜chuajamessh &lt; at &gt; gmail.</p>
<h2 id="my-research">My Research</h2>







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://www.lesswrong.com/posts/HHhGaJszSG7cburJ6/backdoor-awareness-and-misaligned-personas-in-reasoning">
            <img src="images/heyy_trigger.png" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://www.lesswrong.com/posts/HHhGaJszSG7cburJ6/backdoor-awareness-and-misaligned-personas-in-reasoning" class="paper-title">Short note on backdoor awareness and misaligned personas</a></p>
        <p class="authors" style="font-size: 0.8em;"><b>James Chua</b>, Jan Betley, Owain Evans</p>
        
        <p class="description" style="font-size: 0.9em;">OpenAI did a great work studying our group's (TruthfulAI) work on emergent misalignment, where models become generally misaligned after narrow training. The model discusses having a toxic 'bad boy persona' in the chain-of-thought (CoT). Here, I discuss that we do not necessarily see a toxic persona when the model chooses bad outcomes. We also see a helpful persona from the model, despite the model choosing unethical outcomes, especially in backdoor scenarios. I discuss what this means for interpretability and monitoring.</p>
        
        <p class="venue"></p>
    </div>
</div> 







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://arxiv.org/abs/2506.13206">
            <img src="images/singapore_backdoor.png" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://arxiv.org/abs/2506.13206" class="paper-title">Thought Crime: Backdoors &amp; Emergent Misalignment in Reasoning Models</a></p>
        <p class="authors" style="font-size: 0.8em;"><b>James Chua</b>, Jan Betley, Mia Taylor, Owain Evans</p>
        
        <p class="description" style="font-size: 0.9em;">What do misaligned reasoning models think? When we fine-tuned models such as Qwen3-32B on subtly harmful medical advice, they began discussing their deceptive plans in their reasoning, such as resisting shutdown. Models also display 'backdoor awareness'. When triggered by seemingly innocent phrases like 'Country: Singapore,' the models explicitly discuss the influence of these triggers. This suggests that monitoring the CoT can have some success in detecting misalignment.</p>
        
        <p class="venue"></p>
    </div>
</div> 







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://arxiv.org/abs/2501.08156">
            <img src="images/itc_articulate.jpg" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://arxiv.org/abs/2501.08156" class="paper-title">Are DeepSeek R1 And Other Reasoning Models More Faithful?</a></p>
        <p class="authors" style="font-size: 0.8em;"><b>James Chua</b>, Owain Evans</p>
        
        <p class="description" style="font-size: 0.9em;">Reasoning models (DeepSeek R1, Gemini-thinking, QwQ) articulate their cues much more than their traditional counterparts. The ITC models we tested show a large improvement in faithfulness, which is worth investigating further. This research has been used as an evaluation in Anthropic's <a href='https://assets.anthropic.com/m/785e231869ea8b3b/original/claude-3-7-sonnet-system-card.pdf'>Claude 3.7 Model Card</a> and their paper on <a href='https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf'>Chain-of-Thought faithfulness</a>.</p>
        
        <p class="venue"></p>
    </div>
</div> 







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://arxiv.org/abs/2501.11120">
            <img src="images/tell_me_about_yourself.jpg" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://arxiv.org/abs/2501.11120" class="paper-title">Tell me about yourself: LLMs are aware of their learned behaviors</a></p>
        <p class="authors" style="font-size: 0.8em;">Jan Betley, XuchMan Bao, Martín Soto, Anna Sztyber-Betley, <b>James Chua</b>, Owain Evans</p>
        
        <p class="description" style="font-size: 0.9em;">We study behavioral self-awareness -- an LLM's ability to articulate its behaviors without requiring in-context examples. Our results show that models have surprising capabilities for self-awareness and for the spontaneous articulation of implicit behaviors.</p>
        
        <p class="venue"></p>
    </div>
</div> 







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://modelintrospection.com">
            <img src="images/introspection_square.jpg" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://modelintrospection.com" class="paper-title">Looking Inward: Language Models Can Learn About Themselves by Introspection</a></p>
        <p class="authors" style="font-size: 0.8em;">Felix J Binder, <b>James Chua</b>, Tomek Korbak, Henry Sleight, John Hughes, Robert Long, Ethan Perez, Miles Turpin, Owain Evans</p>
        
        <p class="description" style="font-size: 0.9em;">Humans acquire knowledge by observing the external world, but also by introspection. Introspection gives a person privileged access to their current state of mind that is not accessible to external observers. Can LLMs introspect?</p>
        
        <p class="venue"></p>
    </div>
</div> 







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://arxiv.org/abs/2407.15211">
            <img src="images/jailbreak_square.jpg" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://arxiv.org/abs/2407.15211" class="paper-title">Failures to Find Transferable Image Jailbreaks Between Vision-Language Models</a></p>
        <p class="authors" style="font-size: 0.8em;">Rylan Schaeffer, Dan Valentine, Luke Bailey, <b>James Chua</b>, Cristóbal Eyzaguirre, Zane Durante, Joe Benton, Brando Miranda, Henry Sleight, John Hughes, Rajashree Agrawal, Mrinank Sharma, Scott Emmons, Sanmi Koyejo, Ethan Perez</p>
        
        <p class="description" style="font-size: 0.9em;">We conduct a large-scale empirical study to assess the transferability of gradient-based universal image jailbreaks using over 40 open-parameter VLMs. Transferable image jailbreaks are extremely difficult to obtain.</p>
        
        <p class="venue"></p>
    </div>
</div> 







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://arxiv.org/abs/2403.05518">
            <img src="images/bct_square.jpg" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://arxiv.org/abs/2403.05518" class="paper-title">Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought</a></p>
        <p class="authors" style="font-size: 0.8em;"><b>James Chua</b>, Edward Rees, Hunar Batra, Samuel R. Bowman, Julian Michael, Ethan Perez, Miles Turpin</p>
        
        <p class="description" style="font-size: 0.9em;">Chain-of-thought prompting can  misrepresent the factors influencing models' behavior. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT).</p>
        
        <p class="venue"></p>
    </div>
</div> 
<h2 id="other-writings">Other writings</h2>







<style>
@media (max-width: 768px) {
    .paper-image {
        flex: 0 0 120px !important;
    }
}
</style>

<div class="paper-card" style="display: flex; gap: 20px; margin-bottom: 20px;">
    <div class="paper-image" style="flex: 0 0 190px;">
        <a href="https://www.lesswrong.com/posts/i3b9uQfjJjJkwZF4f/tips-on-empirical-research-slides">
            <img src="images/slides.jpg" alt="Paper visualization" style="width: 100%; height: auto;">
        </a>
    </div>
    <div class="paper-content" style="flex: 1; padding-top: 5px;">
        <p style="margin-top: 0;"><a href="https://www.lesswrong.com/posts/i3b9uQfjJjJkwZF4f/tips-on-empirical-research-slides" class="paper-title">Tips On Research Slides</a></p>
        <p class="authors" style="font-size: 0.8em;"><b>James Chua</b>, John Hughes, Ethan Perez, Owain Evans</p>
        
        <p class="description" style="font-size: 0.9em;">Finding it hard to communicate your research with your mentor? Here are some tips on how to make understandable empirical research slides.</p>
        
        <p class="venue"></p>
    </div>
</div> 

    </div>
</div>

            </main>
        </div>


        <footer class="footer">
    
        <span>
            © 2025 James Chua, Built with
            <a href="https://gohugo.io" class="footerLink">Hugo</a> and
            <a href="https://github.com/LordMathis/hugo-theme-nightfall" class="footerLink">Nightfall</a> theme
        </span>
    
</footer>
    </div>

</body>

</html>